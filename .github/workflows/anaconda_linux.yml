name: Anaconda-Linux

on:
  workflow_dispatch:
    inputs:
      python_version:
        required: true
        type: string
      ref:
        required: false
        type: string
      check_run_id:
        required: false
        type: string

env:
  COMMIT: ${{ inputs.ref || github.event.ref }}
  PEM: ${{ secrets.BOT_PEM }}
  GITHUB_RUN_ID: ${{ github.run_id }}
  GITHUB_CHECK_RUN_ID: ${{ inputs.check_run_id }}

jobs:
  Anaconda-Linux:
    runs-on: ubuntu-latest
    name: Unit tests

    steps:
      - uses: actions/checkout@v3
        with:
          ref: ${COMMIT}
      - name: Install dependencies
        uses: ./.github/actions/linux_install
      - uses: conda-incubator/setup-miniconda@v2
        with:
          auto-update-conda: true
          auto-activate-base: true
          python-version: ${{ inputs.python_version }}
      - name: "Setup"
        id: token
        run: |
          pip install jwt requests
          python ci_tools/setup_check_run.py
      - name: Install python dependencies
        uses: ./.github/actions/conda_installation
        with:
          mpi_type: openmpi
      - name: Coverage install
        uses: ./.github/actions/coverage_install
      - name: Fortran/C tests with pytest
        id: f_c_pytest
        timeout-minutes: 60
        uses: ./.github/actions/pytest_run
        with:
          shell_cmd: "bash -l {0}"
      - name: Python tests with pytest
        id: python_pytest
        timeout-minutes: 20
        uses: ./.github/actions/pytest_run_python
        with:
          shell_cmd: "bash -l {0}"
      - name: Parallel tests with pytest
        id: parallel
        timeout-minutes: 20
        uses: ./.github/actions/pytest_parallel
        with:
          shell_cmd: "bash -l {0}"
      - name: Collect coverage information
        continue-on-error: True
        uses: ./.github/actions/coverage_collection
      - name: Save code coverage report
        uses: actions/upload-artifact@v3
        with:
          name: coverage-artifact
          path: .coverage
          retention-days: 1
      - name: "Post completed"
        if: always()
        run:
          python ci_tools/complete_check_run.py ${{ steps.f_c_pytest.outcome }} ${{ steps.python_pytest.outcome }} ${{ steps.parallel.outcome }}
