name: Linux unit tests

on:
  workflow_dispatch:
    inputs:
      python_version:
        required: true
        type: string
      ref:
        required: false
        type: string
      check_run_id:
        required: false
        type: string
      pr_repo:
        required: false
        type: string
      force:
        required: false
        type: boolean
        default: false
  push:
    branches: [devel, main]

env:
  COMMIT: ${{ inputs.ref || github.event.ref }}
  PEM: ${{ secrets.BOT_PEM }}
  GITHUB_RUN_ID: ${{ github.run_id }}
  GITHUB_CHECK_RUN_ID: ${{ inputs.check_run_id }}
  PR_REPO: ${{ inputs.pr_repo || github.repository }}

jobs:
  matrix_prep:
    runs-on: ubuntu-latest
    if: github.event_name != 'push' || github.repository == 'pyccel/pyccel'
    outputs:
      matrix: ${{ steps.set-matrix.outputs.matrix }}
    steps:
    - id: push-matrix
      if: github.event_name == 'push'
      run: |
        echo "matrix=['3.9', '3.10', '3.11', '3.12', '3.13']" >> $GITHUB_ENV
      shell: bash
    - id: dispatch-matrix
      if: github.event_name == 'workflow_dispatch'
      run: |
        echo "matrix=[${{ inputs.python_version }}]" >> $GITHUB_ENV
      shell: bash
    - id: set-matrix
      run: |
        echo "$matrix"
        echo "matrix={\"python_version\": $matrix}" >> $GITHUB_OUTPUT
      shell: bash

  Linux:

    runs-on: ubuntu-latest
    name: Unit tests
    needs: matrix_prep
    strategy:
      matrix: ${{fromJson(needs.matrix_prep.outputs.matrix)}}

    steps:
      - id: duplicate_check
        uses: fkirc/skip-duplicate-actions@v5
        with:
          # All of these options are optional, so you can remove them if you are happy with the defaults
          skip_after_successful_duplicate: 'true'
          paths: '["pyccel/**/*.py", "tests/**/*.py", "pyccel/extensions/**", ".github/workflows/linux.yml", ".github/actions/**"]'
          paths_ignore: '["pyccel/version.py"]'
          do_not_skip: '["push"]'

      - uses: actions/checkout@v4
        with:
          ref: ${{ env.COMMIT }}
          repository: ${{ env.PR_REPO }}
          submodules: true
      - name: Set up Python ${{ matrix.python_version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python_version }}
      - name: "Setup"
        if: github.event_name != 'push'
        id: token
        run: |
          pip install jwt requests
          python ci_tools/setup_check_run.py linux
      - name: Install dependencies
        if: steps.duplicate_check.outputs.should_skip != 'true' || inputs.force
        uses: ./.github/actions/linux_install
      - name: Install Pyccel with tests
        if: steps.duplicate_check.outputs.should_skip != 'true' || inputs.force
        run: |
          python -m pip install --upgrade pip
          python -m pip install .[test] "numpy==2.1"
        shell: bash
      - name: Coverage install
        if: steps.duplicate_check.outputs.should_skip != 'true' || inputs.force
        uses: ./.github/actions/coverage_install
      - name: Fortran/C tests with pytest
        if: steps.duplicate_check.outputs.should_skip != 'true' || inputs.force
        id: f_c_pytest
        timeout-minutes: 60
        uses: ./.github/actions/pytest_run
      - name: Python tests with pytest
        if: steps.duplicate_check.outputs.should_skip != 'true' || inputs.force
        id: python_pytest
        timeout-minutes: 20
        uses: ./.github/actions/pytest_run_python
      - name: Parallel tests with pytest
        if: steps.duplicate_check.outputs.should_skip != 'true' || inputs.force
        id: parallel
        timeout-minutes: 20
        uses: ./.github/actions/pytest_parallel
      - name: Test with valgrind for memory leaks
        if: steps.duplicate_check.outputs.should_skip != 'true' || inputs.force
        id: valgrind
        uses: ./.github/actions/valgrind_run
      - name: Collect coverage information
        if: steps.duplicate_check.outputs.should_skip != 'true' || inputs.force
        continue-on-error: True
        uses: ./.github/actions/coverage_collection
      - name: Collect pre-existing coverage information
        if: steps.duplicate_check.outputs.should_skip == 'true' && ! inputs.force
        uses: actions/download-artifact@v4
        with:
          name: coverage-artifact-${{ matrix.python_version }}
          path: .coverage
          run-id: ${{ fromJSON(steps.duplicate_check.outputs.skipped_by).id }}
          github-token: ${{ github.token }}
      - name: Save code coverage report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-artifact-${{ matrix.python_version }}
          path: .coverage
          retention-days: 3
          include-hidden-files: true
      - name: "Post completed"
        if: always() && github.event_name != 'push' && (steps.duplicate_check.outputs.should_skip != 'true' || inputs.force)
        run:
          python ci_tools/complete_check_run.py ${{ steps.f_c_pytest.outcome }} ${{ steps.python_pytest.outcome }} ${{ steps.parallel.outcome }} ${{ steps.valgrind.outcome }}
      - name: "Post completed"
        if: always() && github.event_name != 'push' && (steps.duplicate_check.outputs.should_skip == 'true' && ! inputs.force)
        run:
          python ci_tools/complete_check_run.py 'success'
