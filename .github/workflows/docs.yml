name: Documentation

on:
  workflow_dispatch:
    inputs:
      python_version:
        required: true
        type: string
      ref:
        required: false
        type: string
      base:
        required: true
        type: string
      check_run_id:
        required: false
        type: string
      pr_repo:
        required: false
        type: string
  pull_request:
    types:
      - opened
      - reopened
      - synchronize
      - ready_for_review

env:
  COMMIT: ${{ inputs.ref || github.event.ref }}
  PEM: ${{ secrets.BOT_PEM }}
  GITHUB_RUN_ID: ${{ github.run_id }}
  GITHUB_CHECK_RUN_ID: ${{ inputs.check_run_id }}
  PR_REPO: ${{ inputs.pr_repo || github.repository }}
  PYTHON_VERSION: ${{ inputs.python_version || '3.10' }}
  BASE: ${{ inputs.base || github.event.pull_request.base.sha }}

jobs:

  DocumentationChecker:

    runs-on: ubuntu-latest
    name: Documentation (docs, ${{ inputs.python_version || '3.10' }})
    if: (github.event_name != 'pull_request' || github.event.pull_request.draft == false)

    steps:
      - id: duplicate_check
        uses: fkirc/skip-duplicate-actions@v5
        with:
          # All of these options are optional, so you can remove them if you are happy with the defaults
          skip_after_successful_duplicate: 'true'
          paths: '["pyccel/**/*.py"]'
          paths_ignore: '["pyccel/version.py"]'
          do_not_skip: '[]'

      - uses: actions/checkout@v4
        with:
          ref: ${{ env.BASE }}
          path: base
          submodules: true
      - uses: actions/checkout@v4
        with:
          path: compare
          ref: ${{ env.COMMIT }}
          repository: ${{ env.PR_REPO }}
          fetch-depth: 0
          submodules: true
      - name: Set up Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - name: "Setup check run"
        if: github.event_name != 'pull_request'
        id: token
        run: |
          pip install jwt requests
          cd compare
          python ../base/ci_tools/setup_check_run.py docs
          cd ..
      - name: Install python CI dependencies
        if: steps.duplicate_check.outputs.should_skip != 'true'
        run: |
          python -m pip install --upgrade pip
          python -m pip install docstr-coverage
          python -m pip install numpydoc
          python -m pip install defusedxml # All imported modules must be available for numpydoc
        shell: bash
      - name: Install dependencies
        if: steps.duplicate_check.outputs.should_skip != 'true'
        uses: ./compare/.github/actions/linux_install
      - name: Install python dependencies for pyccel and tests
        if: steps.duplicate_check.outputs.should_skip != 'true'
        run: |
          cd compare
          pip3 install .[test]
          pip3 install hatchling
          cd ..
        shell: bash
      - name: Check doc coverage
        if: steps.duplicate_check.outputs.should_skip != 'true'
        id: doc_coverage
        run: |
          docstr-coverage --config=base/.docstr.yaml base/pyccel base/ci_tools 2>&1 | tee base_cov
          docstr-coverage --config=compare/.docstr.yaml compare/pyccel compare/ci_tools 2>&1 | tee compare_cov
          export PYTHONPATH=compare
          python compare/ci_tools/summarise_doccoverage.py compare_cov base_cov $GITHUB_STEP_SUMMARY
        shell: bash
      - name: Check doc format
        if: steps.duplicate_check.outputs.should_skip != 'true'
        id: doc_format
        run: |
          cd compare
          git diff ${{ env.BASE }}..HEAD --no-indent-heuristic --unified=0 --output=pull_diff.txt --no-color
          python ci_tools/list_docs_tovalidate.py pull_diff.txt objects.txt
          touch report.txt
          export PYTHONPATH=ci_tools
          while read line; do
            echo "python -m numpydoc validate $line"
            python -m numpydoc validate $line 2>&1 | tee -a report.txt || true
          done < objects.txt
          cd ..
          export PYTHONPATH=compare
          python compare/ci_tools/process_results.py compare/report.txt $GITHUB_STEP_SUMMARY
        shell: bash
      - name: Check doc generation
        if: steps.duplicate_check.outputs.should_skip != 'true'
        id: sphinx_format
        run: |
          cd compare
          python -m pip install -r docs/requirements.txt
          make -C docs html
        shell: bash
      - name: Setup Pages
        if: steps.duplicate_check.outputs.should_skip != 'true' && github.event_name == 'pull_request'
        uses: actions/configure-pages@v3
      - name: Upload artifact
        if: steps.duplicate_check.outputs.should_skip != 'true' && github.event_name == 'pull_request'
        uses: actions/upload-pages-artifact@v3
        with:
          path: 'compare/docs/build/html'
      - name: "Post completed"
        if: always() && github.event_name != 'pull_request' && steps.duplicate_check.outputs.should_skip != 'true'
        run:
          python base/ci_tools/complete_check_run.py ${{ steps.doc_coverage.outcome }} ${{ steps.doc_format.outcome }} ${{ steps.sphinx_format.outcome }}
        shell: bash -l {0}
      - name: "Post completed"
        if: always() && github.event_name != 'pull_request' && steps.duplicate_check.outputs.should_skip == 'true'
        run:
          python base/ci_tools/complete_check_run.py 'success'
        shell: bash -l {0}
